# -*- coding: utf-8 -*-
"""GhostTraffic.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fetZhbp2rxztn-RrFDh0PWIGNgyrEvOY
"""

!pip install langchain replicate sentence-transformers chromadb pypdf

from getpass import getpass
import os

REPLICATE_API_TOKEN = getpass()
os.environ["REPLICATE_API_TOKEN"] = "Your key"

from langchain.llms import Replicate

llama2_13b = "meta/llama-2-13b-chat:Your key"
llm = Replicate(
    model=llama2_13b,
    model_kwargs={"temperature": 0.01, "top_p": 1, "max_new_tokens":500}
)

import pandas as pd

question = "I have data with columns: latitutde, longitude, severity, delay time and other weather related information. How can we use that to tell the drivers what their average speed shoul be to avoid 'Ghost traffic'"
answer = llm(question)
print(answer)

df = pd.read_csv("us_congestion_2016_2022_sample_2m.csv")
df.head()

description = ' '.join(df['Description'])
print(description[:100])

# chat history not passed so Llama doesn't have the context and doesn't know this is more about the book
followup = f"based on the descriptions {description[:500]}. Can you tell us something more?"
followup_answer = llm(followup)
print(followup_answer)

# chat history not passed so Llama doesn't have the context and doesn't know this is more about the book
followup3 = f"based on the data {df[:500]}. What other insights can you provide?"
followup_answer3 = llm(followup3)
print(followup_answer3)

# chat history not passed so Llama doesn't have the context and doesn't know this is more about the book
followup4 = f"based on the data {df[:500]}. What other insights can you provide that will help us build a model to suggest optimum speed to the drivers to avoid Ghost Traffic?"
followup_answer4 = llm(followup4)
print(followup_answer4)

# chat history not passed so Llama doesn't have the context and doesn't know this is more about the book
followup5 = f"based on the data {df}. What other insights can you provide that will help us build a model to suggest optimum speed to the drivers to avoid Ghost Traffic?"
followup_answer5 = llm(followup5)
print(followup_answer5)
